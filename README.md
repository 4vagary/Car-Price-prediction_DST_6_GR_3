![## Car Price prediction - DST 6 GR 3](https://whatcar.vn/media/2018/09/car-lot-940x470.jpg)


## Car Price prediction - DST 6 GR 3 - Прогнозирование стоимости автомобиля по характеристикам
=====================

Поставлена задача создать модель, которая будет предсказывать стоимость автомобиля по его характеристикам. При этом датасет нужно собрать самостоятельно. 


## Сбор данных (парсинг) и подготовка датасетов

В ходе выполнения задания были собраны три полноценных датасета:
- с auto.ru,
- c drom.ru, 
- с auto.ru - дополнительный страхующий вариант. 

Для подготовки и упорядочивания данных использовался важный формат **X-FORMAT**, благодаря которому датасеты уже в процессе создания были приведены к виду тестового датасета:

- порядок и названия признаков приведены в соответствие к формату TEST,
- выделены и выбраны только необходимые марки автомобилей,
- выделены другие признаки, которые важны при формировании датасета (автомобиль должен быть "растаможен", "не требовать ремонта" и т.д.).

На этапе формирования датасетов уже проведена большая работа, при этом полученные данные "чистые" и упорядоченные. 


## Обработка признаков датасета

Обработка признаков осуществлялась в следующем порядке:
1) сброс строк тестового датасета с нулевой ценой,
2) поиск пропусков и замена их на определенные значения (0, медиана и т.д.),
3) приведение соответствующих признаков в тестовом и тренировочном датасетах к одному формату,
4) объединение test и train в один датасет для одинакового кодирования признаков,
5) приведение в общем датасете всех признаков к формату типа "int" или "float", в том числе кодирование с использованием get_dummies,
6) сброс незакодированных и необработанных признаков,
7) разделение общего датасета обратно на тестовую и тренировочную выборки.

Детали выполнения обработки, осставшиеся "за кадром":
- кодирование признака "комплектация" не повлияло на результат, показанный моделью,
- лемматизация и векторизация (word2vec) текста признака "описание" ухудшило результат,
- большинство опробованных составных признаков, а также удаление лишних признаков не улучшили или, наоборот, ухудшили результат,
- как ни странно, нормализация признаков, хотя она не нужна для выбранной модели, улучшила результат на 0,01%. 


## Выбор модели

- CatBoost - пример, использованный в baseline, показал очень хороший результат, 
- XGBoost - модель показала результат лучше, чем CatBoost, на 2% при первом запуске даже без специального подбора гиперпараметров, 
- LightGBM - без дополнительной настройки параметров модель показала результат на 2% хуже, чем CatBoost. После подбора и настройки параметров (не глубокой) результат удалось улучшить не более, чем на 2%. 

Для решения задачи была выбрана модель XGBoost.


## Подготовка и сохранение результата

При сохранении результата было использовано округление до 500, округление до 1000 показало худший результат. 

Итоговый score в соревновании на момент завершения конкурса: **10.26068**.


## По итогам проделанной работы

В ходе выполнения работы членам команды удалось достичь как личных целей по обучению, так и командных целей по достижению хорошего результата в соревновании. 
За счет разделения труда между участниками, которые сделали, каждый свой, посильный вклад в общее дело, удалось сэкономить ресурс времени и за достаточно короткий срок прийти к решению поставленной задачи. Совместное обсуждение этапов соревнования и возможностей улучшения результата также возымело свой положительный эффект. 

Несмотря на то, что осталось много неисследованных областей и методов обработки, которые не удалось применить, **команда выступила на соревновании очень достойно, достигла хорошего результата и полна оптимизма для углубления своих знаний и развития своих навыков в области ML в ближайшем будущем**.

Спасибо и до новых встреч!
